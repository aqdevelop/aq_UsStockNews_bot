#!/usr/bin/env python3
"""
í•´ì™¸ì£¼ì‹ ë‰´ìŠ¤ 12ì‹œê°„ ìš”ì•½ë³¸ ìƒì„± (GPT-4o-mini ë²„ì „)
ì¤‘ìš”í•œ ë‰´ìŠ¤ 10ê°œë¥¼ í•œ ê¸€ë¡œ ëª¨ì•„ì„œ í…”ë ˆê·¸ë¨ì— ì „ì†¡
"""

import feedparser
import requests
import json
from datetime import datetime, timedelta
from typing import List, Dict
import os
import sys

# Railway ë¡œê¹…ì„ ìœ„í•œ ë²„í¼ë§ ë¹„í™œì„±í™”
sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

class USStockNewsSummary:
    def __init__(self, telegram_token: str, telegram_chat_id: str, openai_api_key: str, news_priority: str = 'general'):
        self.telegram_token = telegram_token
        self.telegram_chat_id = telegram_chat_id
        self.openai_api_key = openai_api_key
        self.news_priority = news_priority  # 'general', 'tech', 'macro' ë“±
        
        # ì „ì†¡ ê¸°ë¡ íŒŒì¼ ê²½ë¡œ - Railway Volume ì‚¬ìš©
        volume_path = '/data/sent_news_history.json'
        local_path = 'sent_news_history.json'
        
        # /data ë””ë ‰í† ë¦¬ê°€ ìˆìœ¼ë©´ Volume ì‚¬ìš©, ì—†ìœ¼ë©´ ë¡œì»¬ ì‚¬ìš©
        if os.path.exists('/data'):
            self.sent_news_file = volume_path
            print("ğŸ“ Railway Volume ì‚¬ìš©: /data/sent_news_history.json")
        else:
            self.sent_news_file = local_path
            print("ğŸ“ ë¡œì»¬ íŒŒì¼ ì‚¬ìš©: sent_news_history.json")
        
        # í•´ì™¸ì£¼ì‹ RSS í”¼ë“œ ì†ŒìŠ¤
        self.rss_feeds = {
            # ì¢…í•© ë‰´ìŠ¤
            'MarketWatch': 'https://www.marketwatch.com/rss/topstories',
            'Reuters Business': 'https://www.reutersagency.com/feed/?taxonomy=best-topics&post_type=best',
            'Bloomberg Markets': 'https://feeds.bloomberg.com/markets/news.rss',
            'CNBC Top News': 'https://www.cnbc.com/id/100003114/device/rss/rss.html',
            'Yahoo Finance': 'https://finance.yahoo.com/news/rssindex',
            'Investing.com': 'https://www.investing.com/rss/news.rss',
            
            # ê¸°ìˆ ì£¼/ìŠ¤íƒ€íŠ¸ì—…
            'TechCrunch': 'https://techcrunch.com/feed/',
            'The Verge': 'https://www.theverge.com/rss/index.xml',
            
            # ê±°ì‹œê²½ì œ
            'Financial Times': 'https://www.ft.com/?format=rss',
            'Wall Street Journal': 'https://feeds.a.dj.com/rss/RSSMarketsMain.xml',
            
            # í•œêµ­ í•´ì™¸ì£¼ì‹ ë‰´ìŠ¤
            'ì—°í•©ì¸í¬ë§¥ìŠ¤': 'https://news.einfomax.co.kr/news/rss.xml',
            'ì„œìš¸ê²½ì œ': 'https://www.sedaily.com/RSS/S01.xml',
            'í•œêµ­ê²½ì œ': 'https://www.hankyung.com/feed/economy',
        }
    
    def _load_sent_news_history(self) -> Dict:
        """ì „ì†¡ ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
        try:
            if os.path.exists(self.sent_news_file):
                with open(self.sent_news_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âš ï¸ ì „ì†¡ ê¸°ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {'sent_news': []}
    
    def _save_sent_news_history(self, history: Dict):
        """ì „ì†¡ ê¸°ë¡ ì €ì¥"""
        try:
            with open(self.sent_news_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ì „ì†¡ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _clean_old_history(self, history: Dict, days: int = 7) -> Dict:
        """Nì¼ ì´ì „ ê¸°ë¡ ì‚­ì œ"""
        cutoff_date = datetime.now() - timedelta(days=days)
        cutoff_str = cutoff_date.isoformat()
        
        cleaned = {
            'sent_news': [
                news 
                for news in history.get('sent_news', []) 
                if news.get('sent_at', '') > cutoff_str
            ]
        }
        
        removed_count = len(history.get('sent_news', [])) - len(cleaned['sent_news'])
        if removed_count > 0:
            print(f"ğŸ—‘ï¸ {removed_count}ê°œì˜ ì˜¤ë˜ëœ ê¸°ë¡ ì‚­ì œ (7ì¼ ì´ìƒ)")
        
        return cleaned
    
    def _check_duplicate_by_similarity(self, new_news_list: List[Dict], history: Dict) -> List[Dict]:
        """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬í•œ ì£¼ì œì˜ ë‰´ìŠ¤ í•„í„°ë§"""
        if not history.get('sent_news'):
            print("ğŸ“ ì „ì†¡ ê¸°ë¡ ì—†ìŒ - ì¤‘ë³µ ì²´í¬ ìƒëµ")
            return new_news_list
        
        # ìµœê·¼ ì „ì†¡í•œ ë‰´ìŠ¤ ì •ë³´ (ì œëª© + ìš”ì•½)
        past_news_summary = "\n\n".join([
            f"[ê³¼ê±° ë‰´ìŠ¤ {idx+1}] ì œëª©: {news.get('title', '')}\nìš”ì•½: {news.get('summary', '')[:200]}"
            for idx, news in enumerate(history['sent_news'][-30:])  # ìµœê·¼ 30ê°œë§Œ
        ])
        
        # ìƒˆë¡œìš´ ë‰´ìŠ¤ ì •ë³´
        new_news_summary = "\n\n".join([
            f"[ìƒˆ ë‰´ìŠ¤ {idx+1}] ì œëª©: {news.get('title', '')}\nìš”ì•½: {news.get('summary', '')[:200]}"
            for idx, news in enumerate(new_news_list[:50])  # ìµœëŒ€ 50ê°œ
        ])
        
        prompt = f"""ë‹¤ìŒì€ ìµœê·¼ 7ì¼ ì´ë‚´ì— ì´ë¯¸ ì „ì†¡ëœ ë‰´ìŠ¤ë“¤ì…ë‹ˆë‹¤:

{past_news_summary}

---

ë‹¤ìŒì€ ì´ë²ˆì— ì „ì†¡í•˜ë ¤ëŠ” ìƒˆë¡œìš´ ë‰´ìŠ¤ë“¤ì…ë‹ˆë‹¤:

{new_news_summary}

---

**ì‘ì—…**: ìƒˆë¡œìš´ ë‰´ìŠ¤ ì¤‘ì—ì„œ ê³¼ê±° ë‰´ìŠ¤ì™€ **ì£¼ì œë‚˜ ë‚´ìš©ì´ ìœ ì‚¬í•œ ë‰´ìŠ¤**ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

**íŒë‹¨ ê¸°ì¤€**:
1. ê°™ì€ ì‚¬ê±´/ì´ìŠˆë¥¼ ë‹¤ë£¨ëŠ” ê²½ìš° (ì˜ˆ: "í…ŒìŠ¬ë¼ CEO ì¸í„°ë·°" ê´€ë ¨ ë‰´ìŠ¤ë“¤)
2. ê°™ì€ ê¸°ì—…/ì¸ë¬¼ì— ëŒ€í•œ ë™ì¼í•œ ì†Œì‹ (ì˜ˆ: ê°™ì€ ì‹¤ì , ê°™ì€ ë°œí‘œ)
3. ê°™ì€ ì£¼ê°€/ì§€ìˆ˜ì— ëŒ€í•œ ë™ì¼í•œ ë³€ë™ ë‰´ìŠ¤
4. ë‹¨ìˆœíˆ í‚¤ì›Œë“œê°€ ê²¹ì¹˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, **í•µì‹¬ ë‚´ìš©ì´ ì¤‘ë³µ**ë˜ëŠ” ê²½ìš°ë§Œ

**ì¤‘ìš”**: 
- ê°™ì€ ê¸°ì—…/ì¸ë¬¼ì´ ë‚˜ì™€ë„ **ë‹¤ë¥¸ ì‚¬ê±´**ì´ë©´ ì¤‘ë³µ ì•„ë‹˜
- ì£¼ê°€ ë‰´ìŠ¤ëŠ” **ê°™ì€ ë‚ ì§œ, ê°™ì€ ê°€ê²©ëŒ€**ë§Œ ì¤‘ë³µ
- í›„ì† ë³´ë„ë‚˜ ìƒˆë¡œìš´ ì§„ì „ì´ ìˆìœ¼ë©´ ì¤‘ë³µ ì•„ë‹˜

**ì‘ë‹µ í˜•ì‹** (JSONë§Œ):
{{
  "duplicate_news_numbers": [2, 5, 7]  // ì¤‘ë³µì¸ ìƒˆ ë‰´ìŠ¤ ë²ˆí˜¸ë“¤ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´)
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

        try:
            print(f"ğŸ¤– GPTë¡œ ì¤‘ë³µ ì£¼ì œ ê²€ì‚¬ ì¤‘... (ìƒˆ ë‰´ìŠ¤ {len(new_news_list[:50])}ê°œ vs ê³¼ê±° {len(history['sent_news'][-30:])}ê°œ)")
            
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {self.openai_api_key}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'gpt-4o-mini',
                    'messages': [
                        {'role': 'system', 'content': 'ë‹¹ì‹ ì€ ë‰´ìŠ¤ ì¤‘ë³µ ê²€ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.'},
                        {'role': 'user', 'content': prompt}
                    ],
                    'temperature': 0.2,
                    'max_tokens': 500
                },
                timeout=30
            )
            
            if response.status_code != 200:
                print(f"âš ï¸ GPT ì¤‘ë³µ ê²€ì‚¬ ì‹¤íŒ¨: {response.status_code}")
                return new_news_list
            
            result = response.json()
            response_text = result['choices'][0]['message']['content']
            
            # JSON ì¶”ì¶œ
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end].strip()
            elif "```" in response_text:
                json_start = response_text.find("```") + 3
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end].strip()
            
            duplicate_check = json.loads(response_text)
            duplicate_numbers = duplicate_check.get('duplicate_news_numbers', [])
            
            if duplicate_numbers:
                print(f"ğŸ”„ ìœ ì‚¬ ì£¼ì œ ë°œê²¬: {len(duplicate_numbers)}ê°œ ë‰´ìŠ¤ ì œê±°")
                # ì¤‘ë³µ ë²ˆí˜¸ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ë‰´ìŠ¤ë§Œ ë°˜í™˜
                filtered = [
                    news for idx, news in enumerate(new_news_list[:50]) 
                    if (idx + 1) not in duplicate_numbers
                ]
                filtered.extend(new_news_list[50:])
                
                print(f"ğŸ“Š ì¤‘ë³µ ì œê±° í›„: {len(filtered)}ê°œ ë‰´ìŠ¤")
                return filtered
            else:
                print(f"âœ… ìœ ì‚¬ ì£¼ì œ ì—†ìŒ - ëª¨ë“  ë‰´ìŠ¤ ìœ ì§€")
                return new_news_list
            
        except Exception as e:
            print(f"âš ï¸ GPT ì¤‘ë³µ ê²€ì‚¬ ì˜¤ë¥˜: {e}")
            return new_news_list
    
    def _mark_news_as_sent(self, news_list: List[Dict]):
        """ë‰´ìŠ¤ë¥¼ ì „ì†¡ë¨ìœ¼ë¡œ í‘œì‹œ"""
        history = self._load_sent_news_history()
        history = self._clean_old_history(history)
        
        current_time = datetime.now().isoformat()
        
        for news in news_list:
            history['sent_news'].append({
                'title': news['title'],
                'link': news['link'],
                'summary': news['summary'],
                'sent_at': current_time
            })
        
        self._save_sent_news_history(history)
        print(f"âœ… {len(news_list)}ê°œ ë‰´ìŠ¤ ì „ì†¡ ê¸°ë¡ ì €ì¥")
    
    def fetch_rss_news(self, hours: int = 12) -> List[Dict]:
        """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        all_news = []
        
        print(f"ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ (ìµœê·¼ {hours}ì‹œê°„)")
        print(f"   ê¸°ì¤€ ì‹œê°„: {cutoff_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        for source_name, feed_url in self.rss_feeds.items():
            try:
                print(f"ğŸ” {source_name} ìˆ˜ì§‘ ì¤‘...", end=" ")
                feed = feedparser.parse(feed_url)
                count = 0
                
                for entry in feed.entries[:30]:  # ìµœëŒ€ 30ê°œ
                    try:
                        # ë°œí–‰ ì‹œê°„ íŒŒì‹±
                        pub_date = None
                        if hasattr(entry, 'published_parsed') and entry.published_parsed:
                            pub_date = datetime(*entry.published_parsed[:6])
                        elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                            pub_date = datetime(*entry.updated_parsed[:6])
                        
                        # ì‹œê°„ í•„í„°
                        if pub_date and pub_date < cutoff_time:
                            continue
                        
                        # ì œëª©ê³¼ ë§í¬ í•„ìˆ˜
                        title = entry.get('title', '').strip()
                        link = entry.get('link', '').strip()
                        
                        if not title or not link:
                            continue
                        
                        # ìš”ì•½ë¬¸ (description ë˜ëŠ” summary)
                        summary = entry.get('summary', entry.get('description', ''))[:500]
                        
                        all_news.append({
                            'title': title,
                            'link': link,
                            'summary': summary,
                            'source': source_name,
                            'published': pub_date.isoformat() if pub_date else None
                        })
                        count += 1
                    
                    except Exception as e:
                        continue
                
                print(f"âœ… {count}ê°œ")
            
            except Exception as e:
                print(f"âŒ ì‹¤íŒ¨: {e}")
        
        print(f"\nğŸ“Š ì´ ìˆ˜ì§‘: {len(all_news)}ê°œ ë‰´ìŠ¤\n")
        
        # ì¤‘ë³µ ì œê±° (ì œëª© ê¸°ì¤€)
        seen_titles = set()
        unique_news = []
        
        for news in all_news:
            title_lower = news['title'].lower()
            if title_lower not in seen_titles:
                seen_titles.add(title_lower)
                unique_news.append(news)
        
        removed = len(all_news) - len(unique_news)
        if removed > 0:
            print(f"ğŸ”„ ì¤‘ë³µ ì œê±°: {removed}ê°œ (ì œëª© ê¸°ì¤€)")
        
        print(f"ğŸ“Š ìµœì¢… ìˆ˜ì§‘: {len(unique_news)}ê°œ ë‰´ìŠ¤\n")
        
        # GPT ê¸°ë°˜ ìœ ì‚¬ ì£¼ì œ í•„í„°ë§
        history = self._load_sent_news_history()
        filtered_news = self._check_duplicate_by_similarity(unique_news, history)
        
        return filtered_news
    
    def analyze_and_select_top_news(self, news_list: List[Dict], top_n: int = 10) -> List[Dict]:
        """GPTë¥¼ ì‚¬ìš©í•´ ì¤‘ìš” ë‰´ìŠ¤ ì„ ë³„ ë° ìš”ì•½"""
        if not news_list:
            return []
        
        # ë‰´ìŠ¤ ëª©ë¡ì„ GPTì— ì „ë‹¬í•  í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        news_text = "\n\n".join([
            f"[ë‰´ìŠ¤ {idx+1}]\nì œëª©: {news['title']}\nì¶œì²˜: {news['source']}\në§í¬: {news['link']}\në‚´ìš©: {news['summary'][:300]}"
            for idx, news in enumerate(news_list[:100])  # ìµœëŒ€ 100ê°œ
        ])
        
        prompt = f"""ë‹¹ì‹ ì€ í•´ì™¸ì£¼ì‹ íˆ¬ììë¥¼ ìœ„í•œ ë‰´ìŠ¤ íë ˆì´í„°ì…ë‹ˆë‹¤.

ë‹¤ìŒ ë‰´ìŠ¤ë“¤ ì¤‘ì—ì„œ **íˆ¬ììì—ê²Œ ê°€ì¥ ì¤‘ìš”í•œ {top_n}ê°œ**ë¥¼ ì„ ë³„í•˜ê³ , ê° ë‰´ìŠ¤ë¥¼ í•œêµ­ì–´ë¡œ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

**ì„ ë³„ ê¸°ì¤€** (ìš°ì„ ìˆœìœ„):
1. ì£¼ìš” ê¸°ì—…ì˜ ì‹¤ì , M&A, ì‹ ì œí’ˆ ë°œí‘œ
2. ì—°ì¤€(Fed) ê¸ˆë¦¬, ê²½ì œì§€í‘œ, ê±°ì‹œê²½ì œ ì´ìŠˆ
3. ê·œì œ ë³€í™”, ì •ì±… ë°œí‘œ
4. ì£¼ìš” ì§€ìˆ˜ ê¸‰ë“±ë½ ë° ì‹œì¥ ë™í–¥
5. ì„¹í„°ë³„ ì¤‘ìš” ì´ìŠˆ (ê¸°ìˆ , ê¸ˆìœµ, ì—ë„ˆì§€ ë“±)

**ì œì™¸ ê¸°ì¤€**:
- ë‹¨ìˆœ ì˜ê²¬/ë¶„ì„ ê¸°ì‚¬
- ì†Œê·œëª¨ ê¸°ì—… ë‰´ìŠ¤
- ì¤‘ìš”ë„ ë‚®ì€ ë£¨ë¨¸ì„± ê¸°ì‚¬

**ë‰´ìŠ¤ ëª©ë¡**:
{news_text}

**ì‘ë‹µ í˜•ì‹** (JSONë§Œ):
{{
  "selected_news": [
    {{
      "news_number": 1,
      "title": "ì œëª©ì„ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­",
      "summary": "2-3ë¬¸ì¥ í•œêµ­ì–´ ìš”ì•½",
      "importance_score": 95
    }}
  ]
}}

**ì¤‘ìš”**: ì œëª©(title)ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ ì‘ì„±í•˜ì„¸ìš”. ì˜ë¬¸ ì œëª© ì‚¬ìš© ê¸ˆì§€.
ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

        try:
            print(f"ğŸ¤– GPTë¡œ ì¤‘ìš” ë‰´ìŠ¤ {top_n}ê°œ ì„ ë³„ ì¤‘...\n")
            
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {self.openai_api_key}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'gpt-4o-mini',
                    'messages': [
                        {'role': 'system', 'content': 'ë‹¹ì‹ ì€ ê¸ˆìœµ ë‰´ìŠ¤ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.'},
                        {'role': 'user', 'content': prompt}
                    ],
                    'temperature': 0.3,
                    'max_tokens': 2000
                },
                timeout=60
            )
            
            if response.status_code != 200:
                print(f"âŒ GPT ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return []
            
            result = response.json()
            response_text = result['choices'][0]['message']['content']
            
            # JSON ì¶”ì¶œ
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end].strip()
            elif "```" in response_text:
                json_start = response_text.find("```") + 3
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end].strip()
            
            analysis = json.loads(response_text)
            selected = analysis.get('selected_news', [])
            
            # ì„ ë³„ëœ ë‰´ìŠ¤ ë§¤ì¹­
            top_news = []
            for item in selected[:top_n]:
                news_idx = item['news_number'] - 1
                if 0 <= news_idx < len(news_list):
                    original_news = news_list[news_idx]
                    top_news.append({
                        'title': item['title'],
                        'summary': item['summary'],
                        'link': original_news['link'],
                        'source': original_news['source'],
                        'importance': item.get('importance_score', 0)
                    })
            
            print(f"âœ… {len(top_news)}ê°œ ì¤‘ìš” ë‰´ìŠ¤ ì„ ë³„ ì™„ë£Œ\n")
            
            # ì¤‘ìš”ë„ìˆœ ì •ë ¬
            top_news.sort(key=lambda x: x.get('importance', 0), reverse=True)
            
            return top_news
        
        except Exception as e:
            print(f"âŒ GPT ë¶„ì„ ì˜¤ë¥˜: {e}")
            return []
    
    def format_summary_message(self, news_list: List[Dict], time_of_day: str = None) -> str:
        """í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í¬ë§· (MarkdownV2)"""
        
        def escape_markdown(text: str) -> str:
            """MarkdownV2 íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„"""
            special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
            for char in special_chars:
                text = text.replace(char, f'\\{char}')
            return text
        
        # ì‹œê°„ëŒ€ ìë™ íŒë‹¨
        if time_of_day is None:
            current_hour = datetime.now().hour
            time_of_day = 'morning' if current_hour < 12 else 'evening'
        
        # í—¤ë” ì„¤ì •
        if time_of_day == 'morning':
            header = "â˜€ï¸ *ë¯¸êµ­ì£¼ì‹ ëª¨ë‹ë¸Œë¦¬í”„*"
            subheader = "ë¯¸êµ­ ì¥ ë§ˆê° í›„ ì£¼ìš” ë‰´ìŠ¤"
        else:
            header = "ğŸŒ™ *ë¯¸êµ­ì£¼ì‹ ì´ë¸Œë‹ë¸Œë¦¬í”„*"
            subheader = "ë¯¸êµ­ ì¥ ì‹œì‘ ì „í›„ ì£¼ìš” ë‰´ìŠ¤"
        
        today = datetime.now().strftime('%Y\\-%m\\-%d %H:%M KST')
        
        message = f"""{header}
_{subheader}_

ğŸ“… {today}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
        
        # ë‰´ìŠ¤ ëª©ë¡
        for idx, news in enumerate(news_list, 1):
            title = news['title']
            summary = news['summary']
            link = news['link']
            
            # ì´ìŠ¤ì¼€ì´í”„ ì ìš©
            title_escaped = escape_markdown(title)
            summary_escaped = escape_markdown(summary)
            
            message += f"""{idx}\\. *{title_escaped}*
>{summary_escaped} [ì›ë¬¸]({link})

"""
            
            # ë§ˆì§€ë§‰ ë‰´ìŠ¤ê°€ ì•„ë‹ˆë©´ ë¹ˆ ì¤„ ì¶”ê°€
            if idx < len(news_list):
                message += "\n"
        
        # í‘¸í„°
        message += f"""â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì´ {len(news_list)}ê°œ ì£¼ìš” ë‰´ìŠ¤

í•´ì™¸ì£¼ì‹ & ë§¤í¬ë¡œ ì†Œì‹ ìë™ í¬ì›Œë”© ë¬¸ì˜ğŸ‘‡
ğŸ“§ contact@aqresearch\\.com"""
        
        return message
    
    def send_telegram_message(self, message: str, photo_url: str = None):
        """í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡ (ì´ë¯¸ì§€ í¬í•¨ ê°€ëŠ¥)"""
        
        # 1. ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ë¥¼ í•œ ë©”ì‹œì§€ë¡œ ì „ì†¡
        if photo_url:
            print(f"ğŸ“¸ í—¤ë” ì´ë¯¸ì§€ + ë‰´ìŠ¤ í†µí•© ì „ì†¡ ì‹œë„: {photo_url[:50]}...")
            
            photo_url_api = f"https://api.telegram.org/bot{self.telegram_token}/sendPhoto"
            
            max_caption_length = 1000
            
            if len(message) <= max_caption_length:
                # ì§§ìœ¼ë©´ í•œ ë²ˆì— ì „ì†¡
                if photo_url.startswith('http'):
                    photo_payload = {
                        'chat_id': self.telegram_chat_id,
                        'photo': photo_url,
                        'caption': message,
                        'parse_mode': 'MarkdownV2',
                        'disable_web_page_preview': True
                    }
                else:
                    photo_payload = {
                        'chat_id': self.telegram_chat_id,
                        'photo': photo_url,
                        'caption': message,
                        'parse_mode': 'MarkdownV2',
                        'disable_web_page_preview': True
                    }
                
                try:
                    response = requests.post(photo_url_api, json=photo_payload, timeout=30)
                    
                    if response.status_code == 200:
                        print("âœ… ì´ë¯¸ì§€ + ë‰´ìŠ¤ í†µí•© ì „ì†¡ ì„±ê³µ")
                        return
                    else:
                        print(f"âš ï¸ í†µí•© ì „ì†¡ ì‹¤íŒ¨: {response.text}")
                        
                except Exception as e:
                    print(f"âš ï¸ í†µí•© ì „ì†¡ ì˜¤ë¥˜: {e}")
        
        # 2. í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
        url = f"https://api.telegram.org/bot{self.telegram_token}/sendMessage"
        
        if photo_url and len(message) <= 1000:
            return
        
        # ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¸¸ë©´ ë¶„í•  (4096ì ì œí•œ)
        max_length = 4000
        
        if len(message) <= max_length:
            messages = [message]
        else:
            parts = message.split('\n\n')
            messages = []
            current = parts[0] + "\n\n"
            
            for part in parts[1:]:
                if len(current) + len(part) < max_length:
                    current += part + "\n\n"
                else:
                    messages.append(current)
                    current = part + "\n\n"
            
            if current:
                messages.append(current)
        
        for idx, msg in enumerate(messages):
            payload = {
                'chat_id': self.telegram_chat_id,
                'text': msg,
                'parse_mode': 'MarkdownV2',
                'disable_web_page_preview': True
            }
            
            try:
                response = requests.post(url, json=payload, timeout=10)
                if response.status_code == 200:
                    print(f"âœ… ë©”ì‹œì§€ {idx+1}/{len(messages)} ì „ì†¡ ì„±ê³µ")
                else:
                    print(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {response.text}")
            except Exception as e:
                print(f"âŒ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    def run(self, hours: int = 12, top_n: int = 10, header_image_url: str = None, time_of_day: str = None):
        """ì‹¤í–‰
        
        Args:
            hours: ìˆ˜ì§‘í•  ë‰´ìŠ¤ ì‹œê°„ ë²”ìœ„
            top_n: ì„ ë³„í•  ë‰´ìŠ¤ ê°œìˆ˜
            header_image_url: í—¤ë” ì´ë¯¸ì§€ URL
            time_of_day: 'morning', 'evening', None (ìë™)
        """
        print(f"\n{'='*50}")
        print(f"ğŸš€ í•´ì™¸ì£¼ì‹ ë‰´ìŠ¤ {hours}ì‹œê°„ ìš”ì•½ ì‹œì‘ (GPT-4o-mini)")
        print(f"{'='*50}\n")
        
        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
        news_list = self.fetch_rss_news(hours=hours)
        
        if not news_list:
            print("âŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ì¤‘ìš” ë‰´ìŠ¤ ì„ ë³„
        top_news = self.analyze_and_select_top_news(news_list, top_n=top_n)
        
        if not top_news:
            print("âŒ ì„ ë³„ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 3. ìš”ì•½ ë©”ì‹œì§€ ìƒì„±
        summary = self.format_summary_message(top_news, time_of_day=time_of_day)
        
        # 4. í…”ë ˆê·¸ë¨ ì „ì†¡
        print("ğŸ“¤ í…”ë ˆê·¸ë¨ ì „ì†¡ ì¤‘...\n")
        self.send_telegram_message(summary, photo_url=header_image_url)
        
        # 5. ì „ì†¡ëœ ë‰´ìŠ¤ ê¸°ë¡
        self._mark_news_as_sent(top_news)
        
        print(f"\n{'='*50}")
        print(f"âœ… ì™„ë£Œ: {len(top_news)}ê°œ ë‰´ìŠ¤ ìš”ì•½ ì „ì†¡")
        print(f"{'='*50}\n")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    telegram_token = os.getenv('TELEGRAM_BOT_TOKEN')
    telegram_chat_id = os.getenv('TELEGRAM_CHAT_ID')
    openai_api_key = os.getenv('OPENAI_API_KEY')
    header_image_url = os.getenv('HEADER_IMAGE_URL')
    
    if not all([telegram_token, telegram_chat_id, openai_api_key]):
        print("âŒ ì˜¤ë¥˜: í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("\në‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        print("  - TELEGRAM_BOT_TOKEN")
        print("  - TELEGRAM_CHAT_ID")
        print("  - OPENAI_API_KEY")
        print("  - HEADER_IMAGE_URL (ì„ íƒì‚¬í•­)")
        return
    
    bot = USStockNewsSummary(
        telegram_token=telegram_token,
        telegram_chat_id=telegram_chat_id,
        openai_api_key=openai_api_key
    )
    
    # 12ì‹œê°„, ìƒìœ„ 10ê°œ ë‰´ìŠ¤
    bot.run(hours=12, top_n=10, header_image_url=header_image_url)

if __name__ == "__main__":
    main()
